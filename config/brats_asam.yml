# Copyright 2021 Lucas Fidon and Suprosanna Shit

data:
  split: 0.95                          # ratio of data used for training vs validation
  spacing: [1.0, 1.0, 1.0]
  patch_size: [128, 192, 128]
  data_augmentation: "nnUNet"

network:
  model_name: "DynUNet"
  num_deep_supervision: 4

loss:
  loss_name: "WassDice_CE_BraTSv2"     # Wasserstein Dice loss + CE; it comes with the correct class distances matrix for BraTS 2021
  weight_decay: 0

optimization:
  optimizer: "ASAM"
  momentum: 0.99
  lr: 2e-2                           # initial learning rate
  lr_scheduler: "polynomial_decay"   # note that this depends on max_epochs
  batch_size: 2
  val_batch_size: 1                  # batch size used during validation
  max_epochs: 500                   # in nnU-Net 1 epoch = 250 iterations; in our case it is #training cases / batch size
  val_interval: 50                  # interval of epochs between evaluations on the validation dataset
  gradient_clip_l2_norm: 12

log:
  exp_name: "asam_brats21"                 # default name for the experiments using this config file
  message: "3D U-Net pipeline for BraTS 2021"